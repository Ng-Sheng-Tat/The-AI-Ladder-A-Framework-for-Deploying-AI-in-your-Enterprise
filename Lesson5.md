## Third Step in the Ladder: Analyze Data
To leverage trusted, unified data. The analyzing step involves the use of data to build and scale AI models across your enterprise to transform your business
---
**Analyze your data**
Once organizations have been able to collect their data and organize it in a trusted, unified view, they can now tap into that data to build and scale AI models across their business.   

In order to build AI models from the ground up and scale them across the business, organizations need capabilities covering the full AI lifecycle. This includes:
1. Build: At this phase in the AI lifecycle, it is critical to ensure companies use the **right algorithms** to build their models for making predictions.
2. Run or Deploy: Put custom models into production after models is being tested and satisfied, in an application or business process. Once a model is built and running, the question becomes: how can it be **scaled** with trust and transparency? This is where management plays a crucial role. Integrate into your infrastructure and DevOps Cycles starts.
3. Manage: By having the management in place, organizations can track who changed the model, when the model was deployed, and the lineage on the model. By tracking all these items, organizations can ensure their models are not biased, and that they’re explainable and transparent. (Trustworthy, Transparent, Traceable, explanation of the outcome is possible?)

In today’s world of regulations, **General Data Protection Regulation (GDPR), and data privacy laws**, the way organizations engage with AI is under intense scrutiny. Organizations need to manage their AI across the entire AI lifecycle in order to explain either to a consumer, or another business, how their systems came to a decision and why.

For example, a bank needs to be able to tell a consumer what the factors were behind their loan being denied, and what they would need to do to change that decision.  

Ultimately what is needed is **a set of modular components, flexible environments, and tools that make analyzing data and building AI models easier and more accessible**. These tools should be based on open source frameworks which support a multicloud environment, and a full end-to-end automated lifecycle which enables trust and transparency.

For example, fraud activities have only continued to increase at a rapid pace over the years. Fraud is difficult to predict. That’s because the data is overwhelming and information is siloed, making it difficult to get a "360 degree" view.  This leads to false positives or missed alerts, costing companies hundreds of millions of dollars. In this context, data analysis is based upon predictive insights, real-time analysis, sophisticated modeling techniques and automation technologies, all in a governed and secure environment.
---
> "All data originates in real time but most decisions are made on stale data"

Takeaways from Analyze:
1. Build and collaborate
2. Scale across your enterprise
3. Trust and transparency
---
**Analyzing Data**
- collected and well-organized data can be used
- used to build and scale AI models and gain insights from all the data (irregards of its origin)
- data need to be updated and model needs to be trained continuously
- model must be monitored so that it is not biased
