## Lesson 1: Introduction to the AI Ladder and Fundamentals of AI
- The AI Ladder: Data is the fuel for AI (Modernization)
  1. Collect: Make data simple and accessible
  2. Organize: Create a business-ready analytics foundation
  3. Analyze: Build and scale AI with trust and transparency
  4. Infuse: Operationalize AI throughout the business
---
**AI is the new electricity**
AI is one of the greatest challenges and opportunities of our time. It is poised to change the way people work, to change how enterprises operate, and to transform entire industries. AI initiatives offer cost savings while helping organizations predict and shape future outcomes. They do this through automating routine tasks and augmenting human intelligence to allow us to work on more significant responsibilities.  

But AI is not magic, instead it is a series of software and data engineering techniques for making sense out of a vast amount of data. __In order for AI software to learn the information it needs to know to help humans analyze information and make decisions, it must be trained using the data that it needs, making data the foundation and fuel for AI.__  

This produces a unique business challenge for leaders. While most business leaders list improving the use of data as a top priority, only a small percent of them are actually getting what they need from their data
---
In Machine Learning, everything is centered by data.
- Raw data, processed data, algorithm to **predict or explain**, results interpretation based on Business Context
- Results are more to **probabilistic** rather than **deterministic**
- raw data source, cleaned data, train a machine learning model, query trained machine learning model to get the results
- Machine Learning relies on **Data** and **Algorithm** to __explain__ (why data is like that) and to __predict__ the future state based on the current state.
---
**Supervised Learning Algorithm** mostly used for predictions, it learns from labeled and organized cleaned training data, and helps to predict the outcomes for unforeseen data. Examples include predicting fraudulent insurance claims, machinery points of failure, a prospect ability to repay a loan.

**Unsupervised Learning Algorithm** mostly used for anomaly detection and grouping data with a natural affinity. It deals with unorganized data and outliers problems. It does not use an outcome variable. Mostly it is used for segmenting data into groups with a natural affinity. Examples include customer segmentation, Insurance Fraud, Image classification.

**Deep Learning Algorithm** very efficient in working with large amount of data and unstructured data (images and videos). It is based on a family of algorithm called neural networks that aim to emulate how the brain and neuron connections work. They are the black boxes and their predictions are hard to explain and reason. Examples include predicting a gene ontology and gene-function relationships, health predictions based on wearables devices data, and action recognition in videos.

**Reinforcement Learning Algorithm** is when you have a big data input to derive an output that cannot be implicitly programmed and there is infinite amount of the possible output. It is used in scenarios where a mechanisms of reward for success and penalization for failure leads to optimal outcomes. It is used commonly where large amounts of labeled data with the correct input output pairs are not explicitly presented. Works based on rewards and punishment gains. Examples include training a robot to learn specific policies, bidding in advertising, and games.
---
Since machine learning is to predict or explain, and it works by feeding data into algorithm, it has several notable specialization field.
1. **Visual Recognition** process visual information and capable of identifying objects or categorizing images
2. **Speech Recognition** is the ability of a machine or program to identify words and phrases in spoken language and convert them to machine-readable format. Natural Language Processing (NLP) is a branch of science used in this area.
3. **Text Processing** used to understand complex concepts and identify patterns and trends across millions of articles to provide valuable information. It uses NLP as well.
4. **Tone/Empathy** aims to read and respond to emotions to improve communications and to build better AI solutions incorporating emotions as an input.
5. **Robotics** deals with manufacturing industry and construction industry for control, sensory feedback, and information processing. It is the future.
---
AI is about three things which are **predictions, automation, and optimization**.
You needs three drivers things such as **The AI Ladder, Modernize your data environment (into cloud), and open source (database, handoop)** for data and AI.
